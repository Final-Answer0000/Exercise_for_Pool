# 課題1（Webスクレイピング）について
本課題ではWebスクレイピングを行ってもらい、そのソースコード(.pyファイル)と成果物(.csvファイル)を提出してもらう。<br>
<br>
課題1-1と課題1-2の共通部分<br>

1. [ぐるなび](https://www.gnavi.co.jp/)に掲載されている店舗ページ一覧及びそれぞれの店舗の情報を抽出する。
2. 店舗の検索条件は問わない。
3. 成果物の統一フォーマットは「sample.csv」と同じとする。<br>
4. カラムは、「店舗名」「電話番号」「メールアドレス」「都道府県」「市区町村」「番地」「建物名」「URL」「SSL」とする。<br>
5. 「URL」は、ぐるなびの店舗ページ内の「お店のホームページ」の項目で記載されているものを指す。<br>
ただし、この「URL」はページソースから取得できた文字列そのままではなく、実際にブラウザでリンクを開いたときにアドレスバーに表示されるURLとする.<br>
<span style="color: red; ">(※2022/07/07追記： ぐるなびのページソースが変わったことにより、requestsを用いて「お店のホームページ」が取得できない状態なので、 **課題1-1** に関しては「URL」に入れる値は空でよい. ただし、 **課題1-2** についてはseleniumを用いた場合には取得できることが確認できているため変更はなし.)</span>
6. 「SSL」は上述の「URL」のSSL証明書の有無を記述するものであり、TrueかFalseを記述する。
7. 50レコード分情報を抽出してくること。
8. 住所の分割には正規表現を用いること。（特殊な住所以外は分割出来ていれば、完璧でなくてもよい。）
9. 店舗によっては、ぐるなびの店舗ページにメールアドレスやお店のホームページが掲載されていない場合がある。そのような場合はカラム自体は作成したうえで値は空欄でよい。
## 課題1-1
課題1-1では、requestsライブラリを使ってクローリング及びスクレイピングを行う。<br>
### 最低限使用するpythonのライブラリ
1. requests
2. pandas
3. re
4. Beautifulsoup

### 提出するファイル名
- ソースコード: 1-1.py
- 成果物: 1-1.csv

## 課題1-2
課題1-2では、seleniumライブラリを使ってクローリング及びスクレイピングを行う。<br>
### 最低限使用するpythonのライブラリ
1. selenium
2. pandas
3. re

### 提出するファイル名
- ソースコード: 1-2.py
- 成果物: 1-2.csv

### クローリングの仕方
ページ下部の「>」ボタンをクリックしてページ遷移を行うこと。

# 本課題を行う上での注意点
1. リクエスト先のサーバーに不可をかけないために、リクエスト前には必ず3秒のアイドリングタイムを入れること。[参考](https://docs.pyq.jp/column/crawler.html)
2. requests及びseleniumを使用する際は、ユーザーエージェントを設定すること。
3. 成果物のフォーマットを守ること。
4. ソースコードの可読性をある程度意識すること。
5. csvファイルを出力する際、文字化けや表示エラーに注意すること。