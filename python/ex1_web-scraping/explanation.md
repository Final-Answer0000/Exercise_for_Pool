# 課題1（Webスクレイピング）について
本課題ではWebスクレイピングを行ってもらい、そのソースコード(.pyファイル)と成果物(.csvファイル)を提出してもらう。<br>
<br>
課題1-1と課題1-2の共通部分<br>

1. [ぐるなび](https://www.gnavi.co.jp/)に掲載されている店舗ページ一覧及びそれぞれの店舗の情報を抽出する。
2. 店舗の検索条件は問わない。
3. 成果物の統一フォーマットは「sample.csv」と同じとする。<br>
4. カラムは、「店舗名」「電話番号」「メールアドレス」「都道府県」「市区町村」「番地」「建物名」「URL」とする。<br>
5. 「URL」は、ぐるなびの店舗ページ内の「お店のホームページ」の項目で記載されているものを指す。<br>
<span style="color: red; ">(※2022/07/07追記： ぐるなびのページソースが変わったことにより、requestsを用いて「お店のホームページ」が取得できない状態なので、 **課題1-1** に関しては「URL」カラムは空もしくは作成しなくてもよいこととする. ただし、 **課題1-2** についてはseleniumを用いた場合には取得できることが確認できているため変更はなし.)</span>
6. 50レコード分情報を抽出してくること。
7. 住所の分割には正規表現を用いること。（特殊な住所以外は分割出来ていれば、完璧でなくてもよい。）
## 課題1-1
課題1-1では、requestsライブラリを使ってクローリング及びスクレイピングを行う。<br>
### 使用するpythonのライブラリ
1. requests
2. pandas
3. re
4. Beautifulsoup

### 提出するファイル名
- ソースコード: 1-1.py
- 成果物: 1-1.csv

## 課題1-2
課題1-2では、seleniumライブラリを使ってクローリング及びスクレイピングを行う。<br>
### 使用するpythonのライブラリ
1. selenium
2. pandas
3. re

### 提出するファイル名
- ソースコード: 1-2.py
- 成果物: 1-2.csv

### クローリングの仕方
ページ下部の「>」ボタンをクリックしてページ遷移を行うこと。

# 本課題を行う上での注意点
1. リクエスト先のサーバーに不可をかけないために、リクエスト前には必ず3秒のアイドリングタイムを入れること。[参考](https://docs.pyq.jp/column/crawler.html)
2. requests及びseleniumを使用する際は、ユーザーエージェントを設定すること。
3. 成果物のフォーマットを守ること。
4. ソースコードの可読性をある程度意識すること。
5. csvファイルの文字化けに注意すること。